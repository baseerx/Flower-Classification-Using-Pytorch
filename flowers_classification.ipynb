{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the current directory path\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "# Append the \"flowers\" folder to the directory path\n",
    "flowers_path = os.path.join(dir_path, \"flowers\")\n",
    "# Fetch the flowers from the relevant subfolder\n",
    "flowers = os.listdir(flowers_path)\n",
    "\n",
    "\n",
    "# Create a dictionary to store the flowers and their corresponding paths\n",
    "flower_paths = {}\n",
    "\n",
    "# Loop through the flowers\n",
    "for flower in flowers:\n",
    "    # Fetch the path of the flower\n",
    "    flower_path = os.path.join(flowers_path, flower)\n",
    "    # Fetch the images of the flower\n",
    "    flower_images = os.listdir(flower_path)\n",
    "    # Loop through the images\n",
    "    for image in flower_images:\n",
    "        # Fetch the path of the image\n",
    "        image_path = os.path.join(flower_path, image)\n",
    "        # Store the image path in the dictionary\n",
    "        flower_paths[image_path] = flower\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a dictionary with the image paths as keys and the flower names as values\n",
    "# We will convert into dataframe with keys as one column and values as another column\n",
    "flower_paths_df = pd.DataFrame.from_dict(flower_paths, orient='index')\n",
    "flower_paths_df = flower_paths_df.reset_index()\n",
    "flower_paths_df.columns = ['images', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\s...</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\d...</td>\n",
       "      <td>dandelion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\t...</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\d...</td>\n",
       "      <td>dandelion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\d...</td>\n",
       "      <td>dandelion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images     labels\n",
       "0  d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\s...  sunflower\n",
       "1  d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\d...  dandelion\n",
       "2  d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\t...      tulip\n",
       "3  d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\d...  dandelion\n",
       "4  d:\\BASEERX\\MS - Data Science\\Pytorch\\flowers\\d...  dandelion"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "# Shuffle the dataframe\n",
    "flower_paths_df = flower_paths_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "flower_paths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will split the dataframe into train, validation and test dataframes\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(flower_paths_df['images'],flower_paths_df['labels'],test_size=0.2,random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#Convert the images from path to tensors\n",
    "def convert_image_to_tensor(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224,224))\n",
    "    image = np.array(image)\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.permute(2,0,1)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "#Loop through the train images and convert them to tensors\n",
    "\n",
    "train_images = []\n",
    "for image_path in X_Train:\n",
    "    image = convert_image_to_tensor(image_path)\n",
    "    train_images.append(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.stack(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[125, 131,  37,  ..., 152, 171,  20],\n",
       "          [162, 155,  21,  ..., 149, 185,  18],\n",
       "          [156, 145,  59,  ..., 127, 192,  29],\n",
       "          ...,\n",
       "          [224, 209, 193,  ..., 107,  76, 107],\n",
       "          [230, 225, 217,  ...,  93,  68,  78],\n",
       "          [231, 231, 227,  ...,  88,  70,  61]],\n",
       "\n",
       "         [[ 81, 132,  37,  ..., 126, 148,  13],\n",
       "          [101, 160,  35,  ..., 121, 158,   7],\n",
       "          [114, 162,  73,  ...,  98, 163,  14],\n",
       "          ...,\n",
       "          [217, 202, 187,  ...,  94,  59,  77],\n",
       "          [223, 218, 211,  ...,  71,  51,  55],\n",
       "          [224, 224, 220,  ...,  58,  52,  44]],\n",
       "\n",
       "         [[ 35,  50,   9,  ..., 110, 147,  10],\n",
       "          [ 59,  80,   1,  ..., 105, 155,   4],\n",
       "          [ 62,  84,  29,  ...,  80, 158,  11],\n",
       "          ...,\n",
       "          [201, 183, 163,  ...,  26,  11,  33],\n",
       "          [207, 199, 189,  ...,  14,   5,  13],\n",
       "          [207, 206, 201,  ...,  12,   4,   5]]],\n",
       "\n",
       "\n",
       "        [[[218, 207, 155,  ..., 222, 183, 133],\n",
       "          [211, 204, 155,  ..., 226, 185, 144],\n",
       "          [201, 202, 159,  ..., 232, 192, 160],\n",
       "          ...,\n",
       "          [150, 188, 195,  ..., 253, 251, 255],\n",
       "          [129, 190, 199,  ..., 253, 250, 255],\n",
       "          [118, 191, 200,  ..., 253, 249, 255]],\n",
       "\n",
       "         [[243, 246, 208,  ..., 218, 162, 140],\n",
       "          [233, 240, 207,  ..., 222, 165, 150],\n",
       "          [219, 233, 206,  ..., 230, 172, 163],\n",
       "          ...,\n",
       "          [145, 193, 212,  ..., 254, 255, 252],\n",
       "          [122, 192, 213,  ..., 255, 252, 253],\n",
       "          [111, 191, 214,  ..., 255, 250, 253]],\n",
       "\n",
       "         [[247, 241, 125,  ..., 216, 166, 140],\n",
       "          [250, 240, 122,  ..., 220, 168, 148],\n",
       "          [255, 237, 124,  ..., 227, 174, 160],\n",
       "          ...,\n",
       "          [138, 163, 153,  ..., 254, 254, 255],\n",
       "          [113, 168, 162,  ..., 255, 251, 255],\n",
       "          [100, 169, 167,  ..., 255, 250, 255]]],\n",
       "\n",
       "\n",
       "        [[[129, 145, 137,  ...,  99, 113,  97],\n",
       "          [140, 139, 133,  ...,  92, 106, 101],\n",
       "          [150, 135, 133,  ...,  80,  93, 101],\n",
       "          ...,\n",
       "          [121, 138, 149,  ..., 116,  80,  80],\n",
       "          [134, 142, 144,  ..., 115,  90,  93],\n",
       "          [151, 149, 140,  ..., 116, 103, 108]],\n",
       "\n",
       "         [[128, 144, 136,  ...,  91, 107,  92],\n",
       "          [139, 138, 132,  ...,  86, 101,  96],\n",
       "          [149, 134, 132,  ...,  75,  89,  97],\n",
       "          ...,\n",
       "          [117, 134, 147,  ..., 117,  81,  81],\n",
       "          [130, 138, 142,  ..., 116,  90,  93],\n",
       "          [147, 145, 138,  ..., 117, 102, 107]],\n",
       "\n",
       "         [[133, 149, 141,  ..., 102, 115,  99],\n",
       "          [144, 143, 137,  ...,  95, 108, 103],\n",
       "          [154, 139, 137,  ...,  81,  95, 103],\n",
       "          ...,\n",
       "          [117, 135, 147,  ..., 122,  85,  84],\n",
       "          [129, 138, 144,  ..., 122,  95,  98],\n",
       "          [146, 143, 139,  ..., 123, 108, 112]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 20,  18,  16,  ..., 103,  97,  98],\n",
       "          [  1,  19,  21,  ..., 105, 103, 100],\n",
       "          [  6,   9,  28,  ..., 106, 105, 100],\n",
       "          ...,\n",
       "          [213, 213, 209,  ...,   8,   8,  13],\n",
       "          [210, 210, 208,  ...,  17,  14,  14],\n",
       "          [209, 209, 207,  ...,  16,  13,  14]],\n",
       "\n",
       "         [[ 19,  18,  18,  ...,  75,  72,  77],\n",
       "          [  2,  19,  23,  ...,  79,  80,  80],\n",
       "          [  7,  10,  28,  ...,  82,  84,  80],\n",
       "          ...,\n",
       "          [191, 194, 196,  ...,  16,  15,  27],\n",
       "          [191, 192, 194,  ...,  26,  24,  31],\n",
       "          [190, 189, 191,  ...,  29,  26,  32]],\n",
       "\n",
       "         [[ 14,   7,   1,  ...,   4,   1,   0],\n",
       "          [  0,   9,  11,  ...,   4,   2,   0],\n",
       "          [  2,   2,  15,  ...,   0,   1,   0],\n",
       "          ...,\n",
       "          [ 74, 132, 146,  ...,   5,   6,  11],\n",
       "          [ 30,  96, 125,  ...,   8,   8,   9],\n",
       "          [ 12,  77, 115,  ...,   8,   9,  11]]],\n",
       "\n",
       "\n",
       "        [[[188, 189, 191,  ..., 155, 160, 161],\n",
       "          [187, 188, 190,  ..., 156, 160, 163],\n",
       "          [185, 186, 188,  ..., 156, 159, 163],\n",
       "          ...,\n",
       "          [  0,   0,   7,  ...,   0,   0,   0],\n",
       "          [  0,   3,  12,  ...,   2,   0,   0],\n",
       "          [  0,   5,  14,  ...,   4,   0,   0]],\n",
       "\n",
       "         [[192, 193, 195,  ..., 170, 170, 170],\n",
       "          [191, 192, 194,  ..., 170, 172, 173],\n",
       "          [189, 190, 192,  ..., 170, 173, 175],\n",
       "          ...,\n",
       "          [  7,   6,  12,  ...,  30,  32,  34],\n",
       "          [  7,  10,  18,  ...,  28,  30,  34],\n",
       "          [  8,  14,  21,  ...,  26,  30,  33]],\n",
       "\n",
       "         [[217, 218, 220,  ..., 205, 205, 203],\n",
       "          [216, 217, 219,  ..., 205, 206, 205],\n",
       "          [215, 216, 217,  ..., 204, 207, 207],\n",
       "          ...,\n",
       "          [  0,   3,  14,  ...,  72,  71,  69],\n",
       "          [  0,   7,  21,  ...,  72,  70,  66],\n",
       "          [  0,  10,  25,  ...,  75,  72,  66]]],\n",
       "\n",
       "\n",
       "        [[[  0,   0,   0,  ...,   0,   0,   1],\n",
       "          [  0,   0,   0,  ...,   1,   1,   1],\n",
       "          [  0,   0,   0,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[ 45,  45,  46,  ...,  48,  48,  49],\n",
       "          [ 45,  46,  46,  ...,  48,  48,  48],\n",
       "          [ 46,  46,  46,  ...,  48,  48,  48],\n",
       "          ...,\n",
       "          [ 81,  81,  81,  ...,  84,  84,  84],\n",
       "          [ 81,  81,  81,  ...,  84,  84,  84],\n",
       "          [ 81,  81,  81,  ...,  85,  84,  84]],\n",
       "\n",
       "         [[ 97,  97,  98,  ...,  97,  97,  98],\n",
       "          [ 97,  98,  98,  ..., 100, 100, 100],\n",
       "          [ 98,  98,  98,  ..., 100, 100, 100],\n",
       "          ...,\n",
       "          [154, 154, 154,  ..., 164, 164, 164],\n",
       "          [154, 154, 155,  ..., 164, 164, 164],\n",
       "          [154, 154, 155,  ..., 165, 164, 164]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Y_Train:\n",
    "    if i == 'daisy':\n",
    "        Y_Train.replace(i,0,inplace=True)\n",
    "    elif i == 'dandelion':\n",
    "        Y_Train.replace(i,1,inplace=True)\n",
    "    elif i == 'rose':\n",
    "        Y_Train.replace(i,2,inplace=True)\n",
    "    elif i == 'sunflower':\n",
    "        Y_Train.replace(i,3,inplace=True)\n",
    "    elif i == 'tulip':\n",
    "        Y_Train.replace(i,4,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert unknown column Y_Train to tensor\n",
    "Y_Train = torch.from_numpy(np.array(Y_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now We have X_Train, Y_Train in tensor format we will create CNN model for flowers classification\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,3,1)\n",
    "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
    "        self.fc1 = nn.Linear(54*54*16,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,5)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X,2,2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X,2,2)\n",
    "        X = X.view(-1,54*54*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3179, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the CNN model\n",
    "model = CNN()\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Define the training set\n",
    "train = torch.utils.data.TensorDataset(train_images,Y_Train)\n",
    "\n",
    "# Define the training data loader\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#tune the model for 100 epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in train_loader:\n",
    "        X,y = data\n",
    "        model.zero_grad()\n",
    "        output = model(X.float())\n",
    "        loss = criterion(output,y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the test images to tensors\n",
    "\n",
    "test_images = []\n",
    "for image_path in X_Test:\n",
    "    image = convert_image_to_tensor(image_path)\n",
    "    test_images.append(image)\n",
    "\n",
    "test_images = torch.stack(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the test labels to tensors\n",
    "\n",
    "for i in Y_Test:\n",
    "    if i == 'daisy':\n",
    "        Y_Test.replace(i,0,inplace=True)\n",
    "    elif i == 'dandelion':\n",
    "        Y_Test.replace(i,1,inplace=True)\n",
    "    elif i == 'rose':\n",
    "        Y_Test.replace(i,2,inplace=True)\n",
    "    elif i == 'sunflower':\n",
    "        Y_Test.replace(i,3,inplace=True)\n",
    "    elif i == 'tulip':\n",
    "        Y_Test.replace(i,4,inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Test = torch.from_numpy(np.array(Y_Test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48032407407407407\n"
     ]
    }
   ],
   "source": [
    "#Predicting the test images\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(test_images.float())\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "\n",
    "#Calculating the accuracy of the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(Y_Test, y_pred)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "torch.save(model.state_dict(), 'flowers_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have a test Image\n",
    "test_image = convert_image_to_tensor('test_image.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[232, 232, 232,  ...,  54,  56,  55],\n",
       "          [230, 230, 230,  ...,  55,  54,  52],\n",
       "          [225, 225, 225,  ...,  56,  53,  51],\n",
       "          ...,\n",
       "          [ 17,  17,  16,  ...,  37,  35,  35],\n",
       "          [ 17,  17,  15,  ...,  36,  33,  32],\n",
       "          [ 17,  17,  15,  ...,  33,  31,  30]],\n",
       "\n",
       "         [[241, 241, 241,  ...,  84,  84,  83],\n",
       "          [241, 241, 241,  ...,  85,  85,  84],\n",
       "          [240, 240, 240,  ...,  86,  85,  85],\n",
       "          ...,\n",
       "          [ 25,  25,  26,  ...,  48,  49,  50],\n",
       "          [ 25,  25,  26,  ...,  45,  46,  46],\n",
       "          [ 25,  25,  26,  ...,  42,  43,  44]],\n",
       "\n",
       "         [[ 99,  99,  99,  ...,   0,   0,   0],\n",
       "          [ 91,  91,  91,  ...,   1,   0,   0],\n",
       "          [ 81,  80,  80,  ...,   2,   1,   1],\n",
       "          ...,\n",
       "          [ 12,  12,  12,  ...,  29,  27,  26],\n",
       "          [ 12,  12,  12,  ...,  27,  25,  23],\n",
       "          [ 12,  12,  12,  ...,  23,  22,  21]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "daisy\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(test_image.float())\n",
    "    output = output.argmax(axis=1)\n",
    "    print(output)\n",
    "\n",
    "#converting the output to flower name\n",
    "if output == 0:\n",
    "    flower = 'daisy'\n",
    "    \n",
    "print(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image1=convert_image_to_tensor('sunflower.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n",
      "sunflower\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(test_image1.float())\n",
    "    output = output.argmax(axis=1)\n",
    "    print(output)\n",
    "    if output == 3:\n",
    "        flower = 'sunflower'\n",
    "\n",
    "print(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
